{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns \n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "from helpers import test2submit, import_data\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the dataset and visualizing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_raw, y_train, test_raw = import_data() #Importing the data\n",
    "combine = [train_raw,  test_raw]\n",
    "\n",
    "train_raw.name = 'train_raw'\n",
    "test_raw.name = 'test_raw'\n",
    "test_labels = test_raw['PassengerId']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      "PassengerId    891 non-null int64\n",
      "Survived       891 non-null int64\n",
      "Pclass         891 non-null int64\n",
      "Name           891 non-null object\n",
      "Sex            891 non-null object\n",
      "Age            714 non-null float64\n",
      "SibSp          891 non-null int64\n",
      "Parch          891 non-null int64\n",
      "Ticket         891 non-null object\n",
      "Fare           891 non-null float64\n",
      "Cabin          204 non-null object\n",
      "Embarked       889 non-null object\n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.6+ KB\n",
      "None\n",
      "----------------------------------------\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 418 entries, 0 to 417\n",
      "Data columns (total 11 columns):\n",
      "PassengerId    418 non-null int64\n",
      "Pclass         418 non-null int64\n",
      "Name           418 non-null object\n",
      "Sex            418 non-null object\n",
      "Age            332 non-null float64\n",
      "SibSp          418 non-null int64\n",
      "Parch          418 non-null int64\n",
      "Ticket         418 non-null object\n",
      "Fare           417 non-null float64\n",
      "Cabin          91 non-null object\n",
      "Embarked       418 non-null object\n",
      "dtypes: float64(2), int64(4), object(5)\n",
      "memory usage: 36.0+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(train_raw.info())\n",
    "print('-'*40)\n",
    "print(test_raw.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this initial observation we can see that there are 891 entries. Nevertheless, 2 embarked observations are missing; 177 ages are missing and only 204 cabin values are valid. The cabin values are not going to be used in this analysis, so they will not be touched."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now examine the Number of survival in the following plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Survived:  342\n",
      "Number of Deaths :  549\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = sns.countplot(y_train,label=\"Count\")\n",
    "D, S = y_train.value_counts()\n",
    "\n",
    "print('Number of Survived: ',S)\n",
    "print('Number of Deaths : ',D)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s find out the survival rate by class, sex and age, and plot the results for a better understanding:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Family members feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are not going to analyze the number of Siblings/Spouses or Parents/Children isolatedly. Instead we will study the numbers of family members aboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the variables SibSp (Siblings/Spouses aboard) and Parch (Parents/Children aboard), we can obtain the total number of family members aboard of the Titanic and calculate the proportion of survival"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in combine:\n",
    "    dataset['FamilySize'] = dataset['SibSp'] + dataset['Parch'] + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   FamilySize  Survived\n",
      "0           1  0.303538\n",
      "1           2  0.552795\n",
      "2           3  0.578431\n",
      "3           4  0.724138\n",
      "4           5  0.200000\n",
      "5           6  0.136364\n",
      "6           7  0.333333\n",
      "7           8  0.000000\n",
      "8          11  0.000000\n"
     ]
    }
   ],
   "source": [
    "print(train_raw[['FamilySize', 'Survived']].groupby(['FamilySize'], as_index=False).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that for small family members (2-4) there is a good probability of survival, then we define a categorical variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "family_size_mapping = {2:1, 3:1, 4:1}\n",
    "for dataset in combine:\n",
    "    dataset['small_family'] = dataset['FamilySize'].map(family_size_mapping)\n",
    "    dataset['small_family'] = dataset['small_family'].fillna(0)\n",
    "    dataset['small_family'] = dataset['small_family'].map(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Genre feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in combine:\n",
    "    dataset['Sex'] = dataset['Sex'].map({'male':1, 'female':0})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Age feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x2639eb859e8>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4wLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvqOYd8AAAEXtJREFUeJzt3X1sXXd9x/H3l5aHEEPT0MYLSbUUUXVFeE2J1ZV1muyWh9Ai2j+gKqpQmDLljzEGUybWbtIkJCYVbeXhDzQpoqzZNOqyjq5VxoAqxJuYWCFpC0kJXVmJStMsAZYG3FWAy3d/3ONhZbbvPffx5Jf3S7J8z/E51x/fe/zRz7977nFkJpKkM9+LRh1AktQfFrokFcJCl6RCWOiSVAgLXZIKYaFLUiEsdEkqhIUuSYWw0CWpEOcO85tdcMEFuWnTplr7PPfcc6xevXowgXrU1GzmqqepuaC52cxVT6+5Dhw48MPMvLDthpk5tI8tW7ZkXfv27au9z7A0NZu56mlqrszmZjNXPb3mAvZnBx3rlIskFcJCl6RCWOiSVAgLXZIKYaFLUiEsdEkqhIUuSYWw0CWpEBa6JBViqG/91/BsuvWfVvz6kduvH1ISScPiCF2SCmGhS1IhLHRJKkRHc+gRcQT4CfACMJ+ZkxGxFrgH2AQcAW7KzJODiSlJaqfOCH06Mzdn5mS1fCuwNzMvAfZWy5KkEellyuUGYHd1ezdwY+9xJEnd6rTQE/hyRByIiB3VuvHMPAZQfV43iICSpM5E659htNko4tWZ+UxErAMeBN4PPJCZaxZtczIzz19i3x3ADoDx8fEtMzMztQLOzc0xNjZWa59haWq2ubk5vnfqhRW3mdhw3pDS/FKTH68m5oLmZjNXPb3mmp6ePrBountZHb0ompnPVJ9PRMR9wJXA8YhYn5nHImI9cGKZfXcBuwAmJydzamqqwx+hZXZ2lrr7DEtTs83OznLHV59bcZsjt0wNJ8wiTX68mpgLmpvNXPUMK1fbKZeIWB0Rr1i4DbwFOAQ8AGyrNtsG3D+okJKk9joZoY8D90XEwvafzcwvRsQ3gM9FxHbgKeBdg4spSWqnbaFn5pPA5Uus/xFw7SBCSZLq852iklQIC12SCmGhS1IhLHRJKoSFLkmFsNAlqRAWuiQVwv8pqr5b7v+Z7pyYZ2q4UaSziiN0SSqEhS5JhbDQJakQzqGfpZab5wY4cvv1Q0wiqV8coUtSISx0SSqEhS5JhbDQJakQFrokFcJCl6RCWOiSVAgLXZIKYaFLUiEsdEkqhIUuSYXwWi6qbaXrwEgaHUfoklQIC12SCmGhS1IhnEPX/+McuXRmcoQuSYWw0CWpEBa6JBWi4zn0iDgH2A8czcy3R8TFwAywFngYeE9m/mwwMaX2c/v+L1Sd7eqM0D8AHF60/FHg45l5CXAS2N7PYJKkejoq9IjYCFwPfLpaDuAa4N5qk93AjYMIKEnqTKcj9E8AHwJ+US2/Cng2M+er5aeBDX3OJkmqITJz5Q0i3g5cl5m/FxFTwB8BvwN8LTNfW21zEfCFzJxYYv8dwA6A8fHxLTMzM7UCzs3NMTY2VmufYRl1toNHTy25fnwVHH9+yGE6ML4K1q09r+v9l/t5F0xs6O6+R/08rqSp2cxVT6+5pqenD2TmZLvtOnlR9GrgHRFxHfAy4JW0RuxrIuLcapS+EXhmqZ0zcxewC2BycjKnpqY6+wkqs7Oz1N1nWEad7b3LvEi4c2KeOw427z1jOyfmuamHx2u5n3fBkVu6u+9RP48raWo2c9UzrFxtp1wy87bM3JiZm4Cbga9k5i3APuCd1WbbgPsHllKS1FYvw7g/BmYi4iPAI8Cd/YmkBb4FX1IdtQo9M2eB2er2k8CV/Y8kSeqG7xSVpEJY6JJUCAtdkgphoUtSISx0SSqEhS5JhWje2wlVNC+BKw2OI3RJKoSFLkmFsNAlqRAWuiQVwkKXpEJY6JJUCAtdkgphoUtSISx0SSqEhS5JhbDQJakQFrokFcJCl6RCWOiSVAgLXZIKYaFLUiEsdEkqhIUuSYWw0CWpEP5PUTVKu/85Kml5jtAlqRAWuiQVwkKXpEJY6JJUiLaFHhEvi4ivR8Q3I+KxiPhwtf7iiHgoIp6IiHsi4iWDjytJWk4nI/SfAtdk5uXAZmBrRFwFfBT4eGZeApwEtg8upiSpnbaFni1z1eKLq48ErgHurdbvBm4cSEJJUkciM9tvFHEOcAB4LfAp4C+Af8/M11Zfvwj458x8/RL77gB2AIyPj2+ZmZmpFXBubo6xsbFa+wzLoLMdPHqqq/3GV8Hx5/scpg8GnWtiw3ld7Xc2H2PdMlc9veaanp4+kJmT7bbr6I1FmfkCsDki1gD3AZcttdky++4CdgFMTk7m1NRUJ9/y/8zOzlJ3n2EZdLb3dvkmm50T89xxsHnvGRt0riO3THW139l8jHXLXPUMK1ets1wy81lgFrgKWBMRC7+dG4Fn+htNklRHJ2e5XFiNzImIVcCbgMPAPuCd1WbbgPsHFVKS1F4nf/+uB3ZX8+gvAj6XmXsi4tvATER8BHgEuHOAOSVJbbQt9Mz8FnDFEuufBK4cRChJUn2+U1SSCmGhS1IhLHRJKoSFLkmFsNAlqRAWuiQVonnvD5cGZLn/V7pzYp6p4UaRBsIRuiQVwkKXpEJY6JJUCAtdkgphoUtSISx0SSqEhS5JhbDQJakQFrokFcJCl6RCWOiSVIgz5louy12HY8GR268fUhJJaiZH6JJUCAtdkgphoUtSIc6YOfQStXtdQJLqcIQuSYWw0CWpEBa6JBXCQpekQljoklQIC12SCmGhS1Ih2p6HHhEXAX8D/ArwC2BXZn4yItYC9wCbgCPATZl5cnBRpcHxWkEqQScj9HlgZ2ZeBlwFvC8iXgfcCuzNzEuAvdWyJGlE2hZ6Zh7LzIer2z8BDgMbgBuA3dVmu4EbBxVSktRerTn0iNgEXAE8BIxn5jFolT6wrt/hJEmdi8zsbMOIMeBfgD/PzM9HxLOZuWbR109m5vlL7LcD2AEwPj6+ZWZmplbAubk5xsbGOHj01IrbTWw4r9b99sNCtm61+5m6Nb4Kjj8/kLvuyaBztTsGlnu8O8k1iuMLej/GBsVc9fSaa3p6+kBmTrbbrqNCj4gXA3uAL2Xmx6p1jwNTmXksItYDs5l56Ur3Mzk5mfv37+/oB1gwOzvL1NRUI1+0WsjWrUFdnGvnxDx3HGzeddcGnavdMbDc491JrlG9KNrrMTYo5qqn11wR0VGht51yiYgA7gQOL5R55QFgW3V7G3B/N0ElSf3RyXDpauA9wMGIeLRa9yfA7cDnImI78BTwrsFElCR1om2hZ+ZXgVjmy9f2N44kqVu+U1SSCmGhS1IhLHRJKkTzzm2TutTU/9HaxFNuVSZH6JJUCAtdkgphoUtSIZxDl3rU1Ll7nX0coUtSISx0SSqEhS5JhShmDn2leUzP81WTrXTs3rV19RCT6EznCF2SCmGhS1IhLHRJKoSFLkmFsNAlqRAWuiQVwkKXpEIUcx66NEher0VnAkfoklQIC12SCmGhS1IhnEOXGuzg0VO81+sUqUOO0CWpEBa6JBXCQpekQljoklQIC12SCmGhS1IhLHRJKkTbQo+Iz0TEiYg4tGjd2oh4MCKeqD6fP9iYkqR2Ohmh3wVsPW3drcDezLwE2FstS5JGqG2hZ+a/Av992uobgN3V7d3AjX3OJUmqqds59PHMPAZQfV7Xv0iSpG5EZrbfKGITsCczX18tP5uZaxZ9/WRmLjmPHhE7gB0A4+PjW2ZmZmoFnJubY2xsjINHT9Xab7GJDed1ve9K33d8FaxbO5j77sX4Kjj+/EDuuifmqq9dtl6O7V4s/F42Tam5pqenD2TmZLvtur041/GIWJ+ZxyJiPXBiuQ0zcxewC2BycjKnpqZqfaPZ2VmmpqZWvEBRO0duqfc9F1vp++6cmOemmj9Pp/fdi50T89xxsHnXXTNXfe2y9XJs92Lh97JpzvZc3U65PABsq25vA+7vTxxJUrc6OW3xbuBrwKUR8XREbAduB94cEU8Ab66WJUkj1PbvzMx89zJfurbPWSTVtNL/OvVa6Wcf3ykqSYWw0CWpEBa6JBWimedqFWSlOU5J6idH6JJUCAtdkgphoUtSIc6KOXTnsXU26vW4X+k89oNHT6146QrPgR8NR+iSVAgLXZIKYaFLUiHOijl0SfWtNAe/c2KIQdQxR+iSVAgLXZIKYaFLUiGcQ++R57hLagpH6JJUCAtdkgphoUtSIZxDl9R3vby25HVguucIXZIKYaFLUiEsdEkqhHPokopxtl+n3RG6JBXCQpekQljoklQI59AlnVG8TvvyHKFLUiEsdEkqhIUuSYXoaQ49IrYCnwTOAT6dmbf3JZUkDUC7a8z0cp76Svd919bVXd9vHV2P0CPiHOBTwNuA1wHvjojX9SuYJKmeXqZcrgS+m5lPZubPgBnghv7EkiTV1UuhbwC+v2j56WqdJGkEIjO72zHiXcBbM/N3q+X3AFdm5vtP224HsKNavBR4vOa3ugD4YVchB6+p2cxVT1NzQXOzmaueXnP9amZe2G6jXl4UfRq4aNHyRuCZ0zfKzF3Arm6/SUTsz8zJbvcfpKZmM1c9Tc0Fzc1mrnqGlauXKZdvAJdExMUR8RLgZuCB/sSSJNXV9Qg9M+cj4veBL9E6bfEzmflY35JJkmrp6Tz0zPwC8IU+ZVlO19M1Q9DUbOaqp6m5oLnZzFXPUHJ1/aKoJKlZfOu/JBWi0YUeEVsj4vGI+G5E3DrCHJ+JiBMRcWjRurUR8WBEPFF9Pn8EuS6KiH0RcTgiHouIDzQo28si4usR8c0q24er9RdHxENVtnuqF9SHLiLOiYhHImJPU3JFxJGIOBgRj0bE/mpdE57LNRFxb0R8pzrW3tiQXJdWj9XCx48j4oMNyfaH1XF/KCLurn4fBn6MNbbQG3ZpgbuAraetuxXYm5mXAHur5WGbB3Zm5mXAVcD7qseoCdl+ClyTmZcDm4GtEXEV8FHg41W2k8D2EWQD+ABweNFyU3JNZ+bmRae4NeG5/CTwxcz8NeByWo/byHNl5uPVY7UZ2AL8D3DfqLNFxAbgD4DJzHw9rZNGbmYYx1hmNvIDeCPwpUXLtwG3jTDPJuDQouXHgfXV7fXA4w14zO4H3ty0bMDLgYeB36D15opzl3qOh5hnI61f9GuAPUA0JNcR4ILT1o30uQReCXyP6vW2puRaIudbgH9rQjZ++S76tbROPNkDvHUYx1hjR+g0/9IC45l5DKD6vG6UYSJiE3AF8BANyVZNazwKnAAeBP4TeDYz56tNRvWcfgL4EPCLavlVDcmVwJcj4kD1DmsY/XP5GuAHwF9XU1SfjojVDch1upuBu6vbI82WmUeBvwSeAo4Bp4ADDOEYa3KhxxLrPCVnCRExBvwD8MHM/PGo8yzIzBey9efwRloXc7tsqc2GmSki3g6cyMwDi1cvsekojrWrM/MNtKYZ3xcRvz2CDKc7F3gD8FeZeQXwHKOZ9llWNRf9DuDvR50FoJqzvwG4GHg1sJrWc3q6vh9jTS70ji4tMELHI2I9QPX5xChCRMSLaZX532Xm55uUbUFmPgvM0prnXxMRC+9/GMVzejXwjog4QusKodfQGrGPOheZ+Uz1+QStueArGf1z+TTwdGY+VC3fS6vgR51rsbcBD2fm8Wp51NneBHwvM3+QmT8HPg/8JkM4xppc6E2/tMADwLbq9jZa89dDFREB3AkczsyPNSzbhRGxprq9itZBfhjYB7xzVNky87bM3JiZm2gdU1/JzFtGnSsiVkfEKxZu05oTPsSIn8vM/C/g+xFxabXqWuDbo851mnfzy+kWGH22p4CrIuLl1e/owmM2+GNslC9kdPDiwnXAf9Cae/3TEea4m9Zc2M9pjVi205p33Qs8UX1eO4Jcv0Xrz7ZvAY9WH9c1JNuvA49U2Q4Bf1atfw3wdeC7tP5EfukIn9cpYE8TclXf/5vVx2MLx3tDnsvNwP7qufxH4Pwm5KqyvRz4EXDeonUjzwZ8GPhOdez/LfDSYRxjvlNUkgrR5CkXSVINFrokFcJCl6RCWOiSVAgLXZIKYaFLUiEsdEkqhIUuSYX4Xw2pRT3yOTTzAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_raw['Age'].hist(bins=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "177"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_raw['Age'].isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the Titanic dataset, many (177) of the Age values were given as NaN. \n",
    "\n",
    "An accurate way of guessing missing values is to use other correlated features. In our case we note correlation among Age, Gender, and Pclass. Guess Age values using median values for Age across sets of Pclass and Gender feature combinations. So, median Age for Pclass=1 and Gender=0, Pclass=1 and Gender=1, and so on...\n",
    "\n",
    "Let us start by preparing an empty array to contain guessed Age values based on Pclass x Gender combinations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "guess_ages = np.zeros((2,3))\n",
    "\n",
    "for dataset in combine:\n",
    "    for i in range(0, 2):\n",
    "        for j in range(0, 3):\n",
    "            guess_df = dataset[(dataset['Sex'] == i) & \\\n",
    "                                  (dataset['Pclass'] == j+1)]['Age'].dropna()\n",
    "\n",
    "            # age_mean = guess_df.mean()\n",
    "            # age_std = guess_df.std()\n",
    "            # age_guess = rnd.uniform(age_mean - age_std, age_mean + age_std)\n",
    "\n",
    "            age_guess = guess_df.median()\n",
    "\n",
    "            # Convert random age float to nearest .5 age\n",
    "            guess_ages[i,j] = int( age_guess/0.5 + 0.5 ) * 0.5\n",
    "            \n",
    "    for i in range(0, 2):\n",
    "        for j in range(0, 3):\n",
    "            dataset.loc[ (dataset.Age.isnull()) & (dataset.Sex == i) & (dataset.Pclass == j+1),\\\n",
    "                    'Age'] = guess_ages[i,j]\n",
    "\n",
    "    dataset['Age'] = dataset['Age'].astype(int)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in combine:\n",
    "    dataset['AgeRange'] = pd.cut(dataset['Age'], [-1, 6, 65, 85], labels=['baby', 'child/adult','old'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "survived_by_class = train_raw.groupby('Pclass')['Survived'].mean()\n",
    "survived_by_sex = train_raw.groupby('Sex')['Survived'].mean()\n",
    "survived_by_age = train_raw.groupby('AgeRange')['Survived'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 1.0)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x432 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, (axis1,axis2,axis3) = plt.subplots(1, 3, figsize=(16,6))\n",
    "\n",
    "ax = survived_by_class.plot.bar(ax=axis1, color='#5975A4', title='Survival Rate by Class', sharey=True)\n",
    "ax.set_ylabel('Survival Rate')\n",
    "ax.set_ylim(0.0,1.0)\n",
    "ax = survived_by_sex.plot.bar(ax=axis2, color='#5F9E6E', title='Survival Rate by Sex', sharey=True)\n",
    "ax.set_ylim(0.0,1.0)\n",
    "ax = survived_by_age.plot.bar(ax=axis3, color='#B55D60', title='Survival Rate by Age Range', sharey=True)\n",
    "ax.set_ylim(0.0,1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Title feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Master</td>\n",
       "      <td>0.575000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Miss</td>\n",
       "      <td>0.702703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mr</td>\n",
       "      <td>0.156673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mrs</td>\n",
       "      <td>0.793651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Rare</td>\n",
       "      <td>0.347826</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Title  Survived\n",
       "0  Master  0.575000\n",
       "1    Miss  0.702703\n",
       "2      Mr  0.156673\n",
       "3     Mrs  0.793651\n",
       "4    Rare  0.347826"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for dataset in combine:\n",
    "    dataset['Title'] = dataset.Name.str.extract(' ([A-Za-z]+)\\.', expand=False)\n",
    "\n",
    "    dataset['Title'] = dataset['Title'].replace(['Lady', 'Countess','Capt', 'Col', 'Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\n",
    "\n",
    "    dataset['Title'] = dataset['Title'].replace('Mlle', 'Miss')\n",
    "    dataset['Title'] = dataset['Title'].replace('Ms', 'Miss')\n",
    "    dataset['Title'] = dataset['Title'].replace('Mme', 'Mrs')\n",
    "\n",
    "train_raw[['Title', 'Survived']].groupby(['Title'], as_index=False).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can convert the categorical titles to ordinal.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "title_mapping = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Rare\": 5}\n",
    "age_mapping = {'baby': 0, 'child/adult': 1, 'old':2}\n",
    "embarked_mapping = {'S': 0 , 'C' :1, 'Q':2}\n",
    "\n",
    "for dataset in combine:\n",
    "    dataset['Title'] = dataset['Title'].map(title_mapping)\n",
    "    dataset['Title'] = dataset['Title'].fillna(0).astype('category')\n",
    "    \n",
    "    dataset['AgeRange'] = dataset['AgeRange'].map(age_mapping)\n",
    "    dataset['AgeRange'] = dataset['AgeRange'].fillna(1).astype('category')\n",
    "    \n",
    "    dataset['Embarked'] = dataset['Embarked'].map(embarked_mapping)\n",
    "    dataset['Embarked'] = dataset['Embarked'].fillna(0).astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dropping useless values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_raw.drop(['Survived'], axis = 1, inplace = True)\n",
    "\n",
    "for dataset in combine:\n",
    "    dataset[\"Embarked\"].fillna(method = 'backfill', inplace = True)\n",
    "    #Drop \"useless\" features:\n",
    "    dataset.drop(['PassengerId', 'Name', 'Cabin', 'Age', 'Fare', 'Ticket', 'FamilySize', 'SibSp', 'Parch'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Pclass', 'Sex', 'Embarked', 'small_family', 'AgeRange', 'Title'], dtype='object')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_raw.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_with_dum = pd.DataFrame()\n",
    "#test_with_dum = pd.DataFrame()\n",
    "\n",
    "for dataset in combine:\n",
    "    dum1 = pd.get_dummies(dataset['Embarked'])\n",
    "    dum2 = pd.get_dummies(dataset['Pclass'])\n",
    "    dum3 = pd.get_dummies(dataset['AgeRange'])\n",
    "    dum4 = pd.get_dummies(dataset['Title'])\n",
    "    tmp = dum1.join(dum2).join(dum3).join(dum4)\n",
    "    \n",
    "    if dataset.name == 'train_raw':\n",
    "        train_with_dum = train_raw.copy()\n",
    "        train_with_dum = train_with_dum.drop(['Embarked', 'Pclass', 'AgeRange', 'Title'], axis = 1)\n",
    "        train_with_dum = train_with_dum.join(tmp)\n",
    "        \n",
    "    if dataset.name =='test_raw':\n",
    "        test_with_dum = test_raw.copy()\n",
    "        test_with_dum = test_with_dum.drop(['Embarked', 'Pclass', 'AgeRange', 'Title'], axis = 1)\n",
    "        test_with_dum = test_with_dum.join(tmp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, val_X, train_y, val_y = train_test_split(train_with_dum, y_train, random_state=15, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model, predict and solve\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are ready to train a model and predict the required solution. There are 60+ predictive modelling algorithms to choose from. We must understand the type of problem and solution requirement to narrow down to a select few models which we can evaluate. Our problem is a classification and regression problem. We want to identify relationship between output (Survived or not) with other variables or features (Gender, Age, Port...). We are also perfoming a category of machine learning which is called supervised learning as we are training our model with a given dataset. With these two criteria - Supervised Learning plus Classification and Regression, we can narrow down our choice of models to a few. \n",
    "\n",
    "These include:\n",
    "<ul>\n",
    "    <li>Logistic Regression</li>\n",
    "    <li>KNN or k-Nearest Neighbors</li>\n",
    "    <li>Support Vector Machines</li>\n",
    "    <li>Naive Bayes classifier</li>\n",
    "    <li>Decision Tree</li>\n",
    "    <li>Random Forrest</li>\n",
    "    <li>Perceptron</li>\n",
    "    <li>Artificial neural networ</li>\n",
    "    <li>RVM or Relevance Vector Machine</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Roberto\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "83.24"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(train_X, train_y)\n",
    "Y_pred = logreg.predict(val_X)\n",
    "acc_log = round(logreg.score(val_X, val_y) * 100, 2)\n",
    "acc_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Roberto\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "81.01"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Support Vector Machines\n",
    "svc = SVC()\n",
    "svc.fit(train_X, train_y)\n",
    "Y_pred = svc.predict(val_X)\n",
    "acc_svc = round(svc.score(val_X, val_y) * 100, 2)\n",
    "acc_svc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "83.24"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# K nearest Neighbors\n",
    "knn = KNeighborsClassifier(n_neighbors = 3)\n",
    "knn.fit(train_X, train_y)\n",
    "Y_pred = knn.predict(val_X)\n",
    "acc_knn = round(knn.score(val_X, val_y) * 100, 2)\n",
    "acc_knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "78.77"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Gaussian Naive Bayes\n",
    "gaussian = GaussianNB()\n",
    "gaussian.fit(train_X, train_y)\n",
    "Y_pred = gaussian.predict(val_X)\n",
    "acc_gaussian = round(gaussian.score(val_X, val_y) * 100, 2)\n",
    "acc_gaussian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Roberto\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:144: FutureWarning: max_iter and tol parameters have been added in Perceptron in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "72.07"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Perceptron\n",
    "\n",
    "perceptron = Perceptron()\n",
    "perceptron.fit(train_X, train_y)\n",
    "Y_pred = perceptron.predict(val_X)\n",
    "acc_perceptron = round(perceptron.score(val_X, val_y) * 100, 2)\n",
    "acc_perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80.45"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Linear SVC\n",
    "linear_svc = LinearSVC()\n",
    "linear_svc.fit(train_X, train_y)\n",
    "Y_pred = linear_svc.predict(val_X)\n",
    "acc_linear_svc = round(linear_svc.score(val_X, val_y) * 100, 2)\n",
    "acc_linear_svc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Roberto\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:144: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "42.46"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Stochastic Gradient Descent\n",
    "\n",
    "sgd = SGDClassifier()\n",
    "sgd.fit(train_X, train_y)\n",
    "Y_pred = sgd.predict(val_X)\n",
    "acc_sgd = round(sgd.score(val_X, val_y) * 100, 2)\n",
    "acc_sgd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "85.47"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decision_tree = DecisionTreeClassifier()\n",
    "decision_tree.fit(train_X, train_y)\n",
    "Y_pred = decision_tree.predict(val_X)\n",
    "acc_decision_tree = round(decision_tree.score(val_X, val_y) * 100, 2)\n",
    "acc_decision_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "85.47"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_forest = RandomForestClassifier(n_estimators=100)\n",
    "random_forest.fit(train_X, train_y)\n",
    "Y_pred = random_forest.predict(val_X)\n",
    "acc_random_forest = round(random_forest.score(val_X, val_y) * 100, 2)\n",
    "acc_random_forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>85.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>85.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>KNN</td>\n",
       "      <td>83.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>83.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Support Vector Machines</td>\n",
       "      <td>81.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Linear SVC</td>\n",
       "      <td>80.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>78.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Perceptron</td>\n",
       "      <td>72.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Stochastic Gradient Decent</td>\n",
       "      <td>42.46</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Model  Score\n",
       "3               Random Forest  85.47\n",
       "8               Decision Tree  85.47\n",
       "1                         KNN  83.24\n",
       "2         Logistic Regression  83.24\n",
       "0     Support Vector Machines  81.01\n",
       "7                  Linear SVC  80.45\n",
       "4                 Naive Bayes  78.77\n",
       "5                  Perceptron  72.07\n",
       "6  Stochastic Gradient Decent  42.46"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models = pd.DataFrame({\n",
    "    'Model': ['Support Vector Machines', 'KNN', 'Logistic Regression', \n",
    "              'Random Forest', 'Naive Bayes', 'Perceptron', \n",
    "              'Stochastic Gradient Decent', 'Linear SVC', \n",
    "              'Decision Tree'],\n",
    "    'Score': [acc_svc, acc_knn, acc_log, \n",
    "              acc_random_forest, acc_gaussian, acc_perceptron, \n",
    "              acc_sgd, acc_linear_svc, acc_decision_tree]})\n",
    "models.sort_values(by='Score', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After several recursions, we can see that the modelds more accurate are Random Forest and Decision Trees. We will use these to calculate the final output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LOGISTIC REGRESSION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Scaling\n",
    "\n",
    "sc = StandardScaler()\n",
    "X_train_log = sc.fit_transform(train_with_dum)\n",
    "X_test_log = sc.transform(train_with_dum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Roberto\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=0, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting Logistic Regression to the Training set\n",
    "classifier = LogisticRegression(random_state = 0)\n",
    "classifier.fit(train_with_dum, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict(train_with_dum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_train, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Roberto\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "82.27"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg = LogisticRegression()\n",
    "logreg.fit(train_with_dum, y_train)\n",
    "Y_pred = logreg.predict(test_with_dum)\n",
    "acc_log = round(logreg.score(train_with_dum, y_train) * 100, 2)\n",
    "acc_log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RANDOM FOREST CLASSIFIER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = RandomForestClassifier(n_estimators = 100, criterion = 'entropy', random_state = 0)\n",
    "classifier.fit(train_with_dum, y_train)\n",
    "y_pred_train = classifier.predict(train_with_dum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[517,  32],\n",
       "       [102, 240]], dtype=int64)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_train, y_pred_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8496071829405163"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(517+240)/(517+32+102+240)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test = classifier.predict(test_with_dum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test2submit(test_labels, y_pred_test, ml_method='') #With this file we obtain a 0.79904 (My best entry until now)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "84.96"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decision_tree = DecisionTreeClassifier()\n",
    "decision_tree.fit(train_with_dum, y_train)\n",
    "Y_pred = decision_tree.predict(test_with_dum)\n",
    "acc_decision_tree = round(decision_tree.score(train_with_dum, y_train) * 100, 2)\n",
    "acc_decision_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A submision csv was created\n"
     ]
    }
   ],
   "source": [
    "test2submit(test_labels, y_pred_test, ml_method='dec_tree')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NEURAL NETWORKS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Roberto\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\preprocessing\\data.py:617: DataConversionWarning: Data with input dtype uint8, int64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\Roberto\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\base.py:462: DataConversionWarning: Data with input dtype uint8, int64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "C:\\Users\\Roberto\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:7: DataConversionWarning: Data with input dtype uint8, int64 were all converted to float64 by StandardScaler.\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "#train_X, val_X, train_y, val_y\n",
    "\n",
    "# Feature Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(train_X)\n",
    "X_test = sc.transform(val_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Importing the Keras libraries and packages\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "712/712 [==============================] - 1s 1ms/step - loss: 0.6899 - acc: 0.6264\n",
      "Epoch 2/100\n",
      "712/712 [==============================] - 0s 170us/step - loss: 0.6777 - acc: 0.6264\n",
      "Epoch 3/100\n",
      "712/712 [==============================] - 0s 171us/step - loss: 0.6465 - acc: 0.6264\n",
      "Epoch 4/100\n",
      "712/712 [==============================] - 0s 174us/step - loss: 0.6025 - acc: 0.6264\n",
      "Epoch 5/100\n",
      "712/712 [==============================] - 0s 177us/step - loss: 0.5689 - acc: 0.6264\n",
      "Epoch 6/100\n",
      "712/712 [==============================] - 0s 185us/step - loss: 0.5504 - acc: 0.6264\n",
      "Epoch 7/100\n",
      "712/712 [==============================] - 0s 180us/step - loss: 0.5396 - acc: 0.6264\n",
      "Epoch 8/100\n",
      "712/712 [==============================] - 0s 205us/step - loss: 0.5322 - acc: 0.6264\n",
      "Epoch 9/100\n",
      "712/712 [==============================] - 0s 233us/step - loss: 0.5262 - acc: 0.7458\n",
      "Epoch 10/100\n",
      "712/712 [==============================] - 0s 225us/step - loss: 0.5220 - acc: 0.7963\n",
      "Epoch 11/100\n",
      "712/712 [==============================] - 0s 205us/step - loss: 0.5174 - acc: 0.8132\n",
      "Epoch 12/100\n",
      "712/712 [==============================] - 0s 204us/step - loss: 0.5128 - acc: 0.8188\n",
      "Epoch 13/100\n",
      "712/712 [==============================] - 0s 206us/step - loss: 0.5095 - acc: 0.8202\n",
      "Epoch 14/100\n",
      "712/712 [==============================] - 0s 239us/step - loss: 0.5065 - acc: 0.8216\n",
      "Epoch 15/100\n",
      "712/712 [==============================] - 0s 237us/step - loss: 0.5030 - acc: 0.8202\n",
      "Epoch 16/100\n",
      "712/712 [==============================] - 0s 176us/step - loss: 0.5000 - acc: 0.8202\n",
      "Epoch 17/100\n",
      "712/712 [==============================] - 0s 205us/step - loss: 0.4974 - acc: 0.8202\n",
      "Epoch 18/100\n",
      "712/712 [==============================] - 0s 184us/step - loss: 0.4948 - acc: 0.8202\n",
      "Epoch 19/100\n",
      "712/712 [==============================] - 0s 176us/step - loss: 0.4928 - acc: 0.8188\n",
      "Epoch 20/100\n",
      "712/712 [==============================] - 0s 160us/step - loss: 0.4908 - acc: 0.8202\n",
      "Epoch 21/100\n",
      "712/712 [==============================] - 0s 188us/step - loss: 0.4884 - acc: 0.8174\n",
      "Epoch 22/100\n",
      "712/712 [==============================] - 0s 225us/step - loss: 0.4861 - acc: 0.8202\n",
      "Epoch 23/100\n",
      "712/712 [==============================] - 0s 218us/step - loss: 0.4856 - acc: 0.8202\n",
      "Epoch 24/100\n",
      "712/712 [==============================] - 0s 204us/step - loss: 0.4825 - acc: 0.8188\n",
      "Epoch 25/100\n",
      "712/712 [==============================] - 0s 192us/step - loss: 0.4809 - acc: 0.8188\n",
      "Epoch 26/100\n",
      "712/712 [==============================] - 0s 176us/step - loss: 0.4793 - acc: 0.8188\n",
      "Epoch 27/100\n",
      "712/712 [==============================] - 0s 171us/step - loss: 0.4772 - acc: 0.8188\n",
      "Epoch 28/100\n",
      "712/712 [==============================] - 0s 167us/step - loss: 0.4763 - acc: 0.8188\n",
      "Epoch 29/100\n",
      "712/712 [==============================] - 0s 159us/step - loss: 0.4741 - acc: 0.8174\n",
      "Epoch 30/100\n",
      "712/712 [==============================] - 0s 178us/step - loss: 0.4725 - acc: 0.8202\n",
      "Epoch 31/100\n",
      "712/712 [==============================] - 0s 171us/step - loss: 0.4709 - acc: 0.8202\n",
      "Epoch 32/100\n",
      "712/712 [==============================] - 0s 166us/step - loss: 0.4696 - acc: 0.8202\n",
      "Epoch 33/100\n",
      "712/712 [==============================] - 0s 155us/step - loss: 0.4684 - acc: 0.8188\n",
      "Epoch 34/100\n",
      "712/712 [==============================] - 0s 169us/step - loss: 0.4669 - acc: 0.8188\n",
      "Epoch 35/100\n",
      "712/712 [==============================] - 0s 164us/step - loss: 0.4659 - acc: 0.8216\n",
      "Epoch 36/100\n",
      "712/712 [==============================] - 0s 145us/step - loss: 0.4641 - acc: 0.8230\n",
      "Epoch 37/100\n",
      "712/712 [==============================] - 0s 176us/step - loss: 0.4631 - acc: 0.8216\n",
      "Epoch 38/100\n",
      "712/712 [==============================] - 0s 174us/step - loss: 0.4629 - acc: 0.8188 0s - loss: 0.4791 - acc: 0.80\n",
      "Epoch 39/100\n",
      "712/712 [==============================] - 0s 157us/step - loss: 0.4609 - acc: 0.8258\n",
      "Epoch 40/100\n",
      "712/712 [==============================] - 0s 162us/step - loss: 0.4596 - acc: 0.8202\n",
      "Epoch 41/100\n",
      "712/712 [==============================] - 0s 139us/step - loss: 0.4590 - acc: 0.8272\n",
      "Epoch 42/100\n",
      "712/712 [==============================] - 0s 157us/step - loss: 0.4575 - acc: 0.8230\n",
      "Epoch 43/100\n",
      "712/712 [==============================] - 0s 162us/step - loss: 0.4564 - acc: 0.8230\n",
      "Epoch 44/100\n",
      "712/712 [==============================] - 0s 162us/step - loss: 0.4557 - acc: 0.8230\n",
      "Epoch 45/100\n",
      "712/712 [==============================] - 0s 146us/step - loss: 0.4543 - acc: 0.8258\n",
      "Epoch 46/100\n",
      "712/712 [==============================] - 0s 160us/step - loss: 0.4537 - acc: 0.8244\n",
      "Epoch 47/100\n",
      "712/712 [==============================] - 0s 159us/step - loss: 0.4530 - acc: 0.8216\n",
      "Epoch 48/100\n",
      "712/712 [==============================] - 0s 136us/step - loss: 0.4519 - acc: 0.8272\n",
      "Epoch 49/100\n",
      "712/712 [==============================] - 0s 152us/step - loss: 0.4510 - acc: 0.8258\n",
      "Epoch 50/100\n",
      "712/712 [==============================] - 0s 156us/step - loss: 0.4502 - acc: 0.8272\n",
      "Epoch 51/100\n",
      "712/712 [==============================] - 0s 140us/step - loss: 0.4493 - acc: 0.8272\n",
      "Epoch 52/100\n",
      "712/712 [==============================] - 0s 157us/step - loss: 0.4484 - acc: 0.8301\n",
      "Epoch 53/100\n",
      "712/712 [==============================] - 0s 164us/step - loss: 0.4477 - acc: 0.8287\n",
      "Epoch 54/100\n",
      "712/712 [==============================] - 0s 131us/step - loss: 0.4471 - acc: 0.8272\n",
      "Epoch 55/100\n",
      "712/712 [==============================] - 0s 167us/step - loss: 0.4460 - acc: 0.8272\n",
      "Epoch 56/100\n",
      "712/712 [==============================] - 0s 160us/step - loss: 0.4455 - acc: 0.8301\n",
      "Epoch 57/100\n",
      "712/712 [==============================] - 0s 163us/step - loss: 0.4445 - acc: 0.8301\n",
      "Epoch 58/100\n",
      "712/712 [==============================] - 0s 198us/step - loss: 0.4441 - acc: 0.8287\n",
      "Epoch 59/100\n",
      "712/712 [==============================] - 0s 208us/step - loss: 0.4432 - acc: 0.8301\n",
      "Epoch 60/100\n",
      "712/712 [==============================] - 0s 202us/step - loss: 0.4427 - acc: 0.8315\n",
      "Epoch 61/100\n",
      "712/712 [==============================] - 0s 206us/step - loss: 0.4416 - acc: 0.8301\n",
      "Epoch 62/100\n",
      "712/712 [==============================] - 0s 223us/step - loss: 0.4417 - acc: 0.8315\n",
      "Epoch 63/100\n",
      "712/712 [==============================] - 0s 208us/step - loss: 0.4405 - acc: 0.8301\n",
      "Epoch 64/100\n",
      "712/712 [==============================] - 0s 219us/step - loss: 0.4399 - acc: 0.8315\n",
      "Epoch 65/100\n",
      "712/712 [==============================] - 0s 216us/step - loss: 0.4393 - acc: 0.8329\n",
      "Epoch 66/100\n",
      "712/712 [==============================] - 0s 169us/step - loss: 0.4387 - acc: 0.8329\n",
      "Epoch 67/100\n",
      "712/712 [==============================] - 0s 176us/step - loss: 0.4384 - acc: 0.8343\n",
      "Epoch 68/100\n",
      "712/712 [==============================] - 0s 178us/step - loss: 0.4376 - acc: 0.8301\n",
      "Epoch 69/100\n",
      "712/712 [==============================] - 0s 216us/step - loss: 0.4367 - acc: 0.8315 0s - loss: 0.4297 - acc: 0.836\n",
      "Epoch 70/100\n",
      "712/712 [==============================] - 0s 195us/step - loss: 0.4362 - acc: 0.8301\n",
      "Epoch 71/100\n",
      "712/712 [==============================] - 0s 212us/step - loss: 0.4359 - acc: 0.8329\n",
      "Epoch 72/100\n",
      "712/712 [==============================] - 0s 170us/step - loss: 0.4353 - acc: 0.8301\n",
      "Epoch 73/100\n",
      "712/712 [==============================] - 0s 185us/step - loss: 0.4345 - acc: 0.8301 0s - loss: 0.4101 - acc: 0.85\n",
      "Epoch 74/100\n",
      "712/712 [==============================] - 0s 254us/step - loss: 0.4340 - acc: 0.8329\n",
      "Epoch 75/100\n",
      "712/712 [==============================] - 0s 244us/step - loss: 0.4335 - acc: 0.8329\n",
      "Epoch 76/100\n",
      "712/712 [==============================] - 0s 176us/step - loss: 0.4332 - acc: 0.8329\n",
      "Epoch 77/100\n",
      "712/712 [==============================] - 0s 159us/step - loss: 0.4327 - acc: 0.8329\n",
      "Epoch 78/100\n",
      "712/712 [==============================] - 0s 159us/step - loss: 0.4319 - acc: 0.8329\n",
      "Epoch 79/100\n",
      "712/712 [==============================] - 0s 164us/step - loss: 0.4318 - acc: 0.8258\n",
      "Epoch 80/100\n",
      "712/712 [==============================] - 0s 133us/step - loss: 0.4318 - acc: 0.8329\n",
      "Epoch 81/100\n",
      "712/712 [==============================] - 0s 161us/step - loss: 0.4307 - acc: 0.8329\n",
      "Epoch 82/100\n",
      "712/712 [==============================] - 0s 143us/step - loss: 0.4306 - acc: 0.8329\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83/100\n",
      "712/712 [==============================] - 0s 160us/step - loss: 0.4303 - acc: 0.8287\n",
      "Epoch 84/100\n",
      "712/712 [==============================] - 0s 169us/step - loss: 0.4299 - acc: 0.8329\n",
      "Epoch 85/100\n",
      "712/712 [==============================] - 0s 160us/step - loss: 0.4296 - acc: 0.8329\n",
      "Epoch 86/100\n",
      "712/712 [==============================] - 0s 218us/step - loss: 0.4293 - acc: 0.8329\n",
      "Epoch 87/100\n",
      "712/712 [==============================] - 0s 221us/step - loss: 0.4287 - acc: 0.8287\n",
      "Epoch 88/100\n",
      "712/712 [==============================] - 0s 198us/step - loss: 0.4284 - acc: 0.8315\n",
      "Epoch 89/100\n",
      "712/712 [==============================] - 0s 156us/step - loss: 0.4277 - acc: 0.8329\n",
      "Epoch 90/100\n",
      "712/712 [==============================] - 0s 167us/step - loss: 0.4274 - acc: 0.8301\n",
      "Epoch 91/100\n",
      "712/712 [==============================] - 0s 155us/step - loss: 0.4275 - acc: 0.8315\n",
      "Epoch 92/100\n",
      "712/712 [==============================] - 0s 156us/step - loss: 0.4274 - acc: 0.8301\n",
      "Epoch 93/100\n",
      "712/712 [==============================] - 0s 138us/step - loss: 0.4263 - acc: 0.8329\n",
      "Epoch 94/100\n",
      "712/712 [==============================] - 0s 156us/step - loss: 0.4263 - acc: 0.8329\n",
      "Epoch 95/100\n",
      "712/712 [==============================] - 0s 191us/step - loss: 0.4254 - acc: 0.8315\n",
      "Epoch 96/100\n",
      "712/712 [==============================] - ETA: 0s - loss: 0.4444 - acc: 0.818 - 0s 205us/step - loss: 0.4257 - acc: 0.8258\n",
      "Epoch 97/100\n",
      "712/712 [==============================] - 0s 212us/step - loss: 0.4254 - acc: 0.8315\n",
      "Epoch 98/100\n",
      "712/712 [==============================] - 0s 171us/step - loss: 0.4258 - acc: 0.8272\n",
      "Epoch 99/100\n",
      "712/712 [==============================] - 0s 156us/step - loss: 0.4254 - acc: 0.8315\n",
      "Epoch 100/100\n",
      "712/712 [==============================] - 0s 173us/step - loss: 0.4248 - acc: 0.8329\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x263a36cb240>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialising the ANN\n",
    "classifier = Sequential()\n",
    "\n",
    "# Adding the input layer and the first hidden layer\n",
    "classifier.add(Dense(units = 4, kernel_initializer = 'uniform', activation = 'relu', input_dim = 16))\n",
    "\n",
    "# Adding the second hidden layer\n",
    "classifier.add(Dense(units = 4, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "\n",
    "# Adding the output layer\n",
    "classifier.add(Dense(units = 1, kernel_initializer = 'uniform', activation = 'sigmoid'))\n",
    "\n",
    "# Compiling the ANN\n",
    "classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "# Fitting the ANN to the Training set\n",
    "classifier.fit(train_X, train_y, batch_size = 10, epochs = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict(val_X)\n",
    "y_pred = y_pred > 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[95,  8],\n",
       "       [20, 56]], dtype=int64)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm = confusion_matrix(val_y, y_pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8435754189944135"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(95+56)/(95+56+8+20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
